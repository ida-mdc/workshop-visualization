<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Volumetric data rendering with Neuroglancer | 3D Data Visualization Workshop</title><link type=text/css rel=stylesheet href=/workshop-visualization/css/theme.css><link rel=stylesheet href=/workshop-visualization/reveal/plugin/highlight/monokai.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Urbanist:wght@300;400;500;700&display=swap"><script src=/workshop-visualization/js/main.f2979a93a325fecf9605263bd141398a311c8e23388ed7dcff74f92f7e632866.js integrity="sha256-8peak6Ml/s+WBSY70UE5ijEcjiM4jtfc/3T5L35jKGY=" crossorigin=anonymous></script>
<script>function toggleMetadata(e){const t=document.getElementById("metadata-"+e),n=event.target;t.style.display==="none"||t.style.display===""?t.style.display="flex":t.style.display="none"}</script><script>document.addEventListener("DOMContentLoaded",function(){const t=new URLSearchParams(window.location.search),n=t.get("view"),e=document.getElementById("page-content");if(n==="slides"){e.classList.add("reveal"),e.classList.remove("scroll");const n=e=>{const t=document.createElement("link");t.rel="stylesheet",t.href=e,document.head.appendChild(t)},t=(e,t)=>{const n=document.createElement("script");n.src=e,n.onload=t||function(){},document.body.appendChild(n)};n("/workshop-visualization/reveal/dist/reveal.css"),n("/workshop-visualization/reveal/dist/theme/white-hi.css"),n("/workshop-visualization/reveal/plugin/highlight/monokai.css"),t("/workshop-visualization/reveal/dist/reveal.js",function(){console.log("Reveal.js loaded"),t("/workshop-visualization/reveal/plugin/markdown/markdown.js",function(){t("/workshop-visualization/reveal/plugin/highlight/highlight.js",function(){t("/workshop-visualization/reveal/plugin/notes/notes.js",function(){console.log("All Reveal.js plugins loaded and ready to initialize."),typeof Reveal!="undefined"?Reveal.initialize({hash:!0,slideNumber:!0,center:!1,disableLayout:!0,transition:"fade",display:"flex",plugins:[RevealMarkdown,RevealNotes]}):console.error("Reveal.js is not defined, initialization failed.")})})})})}else e.classList.remove("reveal"),e.classList.add("scroll")})</script><script src=/workshop-visualization/js/jquery.min.js></script>
<script type=text/javascript src=/workshop-visualization/js/jquery.qrcode.js></script>
<script type=text/javascript src=/workshop-visualization/js/qrcode.js></script></head><body><header></header><main><div class=workshop id=page-content><div class=reveal-header><a href="?view=slides" class="toggle-view hidden-in-slides">View as Slides</a><div class=hi-icon></div></div><div class="slides limited-width" id=slides-container><section style=background-image:url(/workshop-visualization/img/neuroglancer.png)><div class=presentation-title><h1>Volumetric data rendering with Neuroglancer</h1><div class=presenter><div>Deborah Schmidt</div><div>Helmholtz Imaging | MDC Berlin</div><div>Sep 25, 2024</div></div><img class=hidden-in-page src=/workshop-visualization/img/RZ_211119_Helmholtz-Imaging_Logo_4C_White.png height=90vh><aside class=notes>Use case description of how to render voxel-based volumetric data using Neuroglancer and stream data locally or remotely for visualization.</aside></div></section><section><nav class=toc><h2>Table of Contents</h2><ul><li><a href=#section-0>Introduction</a></li><li><a href=#section-1>Available datasets</a></li><li><a href=#section-3>Dataset requirements</a></li><li><a href=#section-4>Data preparation</a></li><li><a href=#section-6>Streaming data locally</a></li><li><a href=#section-7>Sharing views</a></li><li><a href=#section-8>Programmatically generate URL</a></li><li><a href=#section-9>Data hosting for Neuroglancer</a></li></ul></nav><div class=qr-code-slides><div id=qr-slides class=qr-code></div><script>jQuery("#qr-slides").qrcode({text:"https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-neuroglancer/"})</script><span>Slides available at <a href=https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-neuroglancer/>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-neuroglancer/</a></span></div></section><section id=section-0><h2 id=introduction>Introduction</h2><aside class=notes><p><strong>Neuroglancer</strong> is a web-based tool for visualizing large-scale 3D datasets such as brain volumes, microscopy
images, and annotations. Neuroglancer allows you to stream volumetric datasets for interactive exploration in the browser.</p><p>This showcase will demonstrate the process of preparing your data for Neuroglancer, streaming it
locally or remotely, and working with the Neuroglancer interface to adjust views, add annotations, and share visualizations with collaborators.</p></aside><h3 id=main-features>Main Features:</h3><ul><li><strong>Voxel-based rendering</strong>: Efficiently visualize large 3D datasets by streaming the data directly into the browser.</li><li><strong>Support for multiple data formats</strong>: Neuroglancer works with a variety of formats like <strong>ZARR</strong> and <strong>OME-ZARR</strong> for volumetric images, as well as annotation formats.</li><li><strong>Interactive, shareable views</strong>: Customize and share views by copying the URL directly from the Neuroglancer interface.</li></ul><div style=flex:1></div><div class=citations><ul><li><a href=https://github.com/google/neuroglancer>Neuroglancer, Google Connectomics Team</a></li></ul></div></section><section id=section-1><h2 id=available-datasets>Available datasets</h2><h2 id=popular-datasets-using-neuroglancer>Popular datasets using Neuroglancer</h2><aside class=notes>Neuroglancer has been used to visualize several large-scale, high-resolution datasets, especially in the fields of neuroscience, biology, and medical imaging. These datasets often involve volumetric scans, such as brain structures, organs, or entire organisms, making Neuroglancer an invaluable tool for researchers who need interactive, 3D visualizations of such complex data.</aside><div class=flex></div><div class=horizontal><ul><li><strong><a href=https://www.microns-explorer.org/>MICrONS Explorer</a></strong>: A large-scale dataset from the <strong>MICrONS Project</strong>, providing high-resolution volumetric reconstructions of a mouse brain.</li><li><strong><a href=https://www.janelia.org/project-team/flyem/hemibrain>FlyEM Hemibrain</a></strong>: This dataset offers a detailed 3D reconstruction of the <strong>Drosophila melanogaster</strong> brain at nanometer resolution.</li><li><strong><a href=https://h01-release.storage.googleapis.com/landing>&ldquo;H01&rdquo; Dataset</a></strong>: 1.4 Petabyte for one cubic millimeter
of the human brain, released by the Harvard University and the Connectomics at Google team.</li></ul><figure><img src=https://ida-mdc.github.io/workshop-visualization/img/the-human-brain.png alt="Screenshot from the H01 Dataset (link)" width=500px><figcaption><p>Screenshot from the H01 Dataset (<a href="https://h01-dot-neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B8e-9%2C%22m%22%5D%2C%22y%22:%5B8e-9%2C%22m%22%5D%2C%22z%22:%5B3.3e-8%2C%22m%22%5D%7D%2C%22position%22:%5B332552.65625%2C141535.84375%2C3487.12451171875%5D%2C%22crossSectionScale%22:5.776802800212544%2C%22projectionOrientation%22:%5B0.00491650216281414%2C0.035930924117565155%2C-0.03526147082448006%2C0.9987198710441589%5D%2C%22projectionScale%22:261570.24038807175%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://h01-release/data/20210601/4nm_raw%22%2C%22tab%22:%22source%22%2C%22name%22:%224nm%20EM%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%5B%7B%22url%22:%22precomputed://gs://h01-release/data/20210601/c3%22%2C%22subsources%22:%7B%22default%22:true%2C%22bounds%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22precomputed://gs://lichtman-h01-49eee972005c8846803ef58fbd36e049/goog14r0s5c3_new_props/segment_properties%22%5D%2C%22panels%22:%5B%7B%22flex%22:1.55%2C%22tab%22:%22segments%22%7D%5D%2C%22segments%22:%5B%221100054524%22%2C%221115430292%22%2C%2212237931142%22%2C%221333290325%22%2C%221538274151%22%2C%221539076840%22%2C%221594648509%22%2C%221638188509%22%2C%221828951844%22%2C%221915887451%22%2C%221988993337%22%2C%2220070214646%22%2C%222090806103%22%2C%222134549398%22%2C%222178704414%22%2C%222294780853%22%2C%222339328448%22%2C%222499107339%22%2C%222499384877%22%2C%222557789796%22%2C%222673254402%22%2C%2227622860459%22%2C%2227651872764%22%2C%2227870683066%22%2C%222791142865%22%2C%2228000894735%22%2C%2228045909614%22%2C%2228378958224%22%2C%2228409678489%22%2C%2228452985548%22%2C%2228525770719%22%2C%2228643309290%22%2C%2228672203772%22%2C%2228802547903%22%2C%2228803598117%22%2C%2228918216929%22%2C%2229021270843%22%2C%2229182786959%22%2C%2229238417446%22%2C%2229298236361%22%2C%222935896346%22%2C%2229459096371%22%2C%2229618159554%22%2C%2229765396306%22%2C%2229925423252%22%2C%2229938695074%22%2C%2229969547791%22%2C%2230101233972%22%2C%223023633866%22%2C%2230376944711%22%2C%2230406000355%22%2C%223052908678%22%2C%2230668773752%22%2C%2230767987832%22%2C%2230871567933%22%2C%2230974109956%22%2C%2231031989065%22%2C%2231032951251%22%2C%2231061717348%22%2C%2231133932587%22%2C%2231149133165%22%2C%223125564306%22%2C%2231658722916%22%2C%2232444986357%22%2C%223430740099%22%2C%223504577656%22%2C%223518943222%22%2C%223573728110%22%2C%2236123853342%22%2C%2236153829678%22%2C%2236241229806%22%2C%2236284756264%22%2C%2236445761568%22%2C%2236590837294%22%2C%2236619747807%22%2C%2236620463168%22%2C%2236633005581%22%2C%223664545249%22%2C%2236662790455%22%2C%2236678107375%22%2C%2236763714196%22%2C%2236809473223%22%2C%2236822073774%22%2C%2236822262086%22%2C%2236852896228%22%2C%2237173591638%22%2C%2237218168369%22%2C%2237318668413%22%2C%2237319791473%22%2C%2237420743412%22%2C%2237421824682%22%2C%2237463700916%22%2C%2237536734693%22%2C%2237581252436%22%2C%2237594612366%22%2C%2237668755920%22%2C%2237770758892%22%2C%2237801070911%22%2C%2237930756265%22%2C%2237958718097%22%2C%2238018479939%22%2C%2238092682277%22%2C%2238106873604%22%2C%2238208029710%22%2C%2238222309348%22%2C%2238339219897%22%2C%2238368158152%22%2C%2238383402139%22%2C%223839697992%22%2C%2238413115427%22%2C%2238543488421%22%2C%2238573083867%22%2C%2238586823171%22%2C%2238602358951%22%2C%2238717924646%22%2C%2238863556782%22%2C%2238863862489%22%2C%223897678996%22%2C%2238994907574%22%2C%2239023934118%22%2C%2239038491013%22%2C%2239052800624%22%2C%2239081564265%22%2C%2239271712983%22%2C%2239271916939%22%2C%2239359991385%22%2C%223941569746%22%2C%2239505037109%22%2C%2239694250521%22%2C%2240043667040%22%2C%2240102203154%22%2C%2240247497000%22%2C%2240378483178%22%2C%2240407875435%22%2C%2240464862282%22%2C%2241354296446%22%2C%2241630488832%22%2C%224217863883%22%2C%224318903980%22%2C%2245701832369%22%2C%224580553370%22%2C%224698412002%22%2C%224784821941%22%2C%2248079386659%22%2C%224917456198%22%2C%224961186471%22%2C%225062824784%22%2C%225499847526%22%2C%2258866575372%22%2C%2259536235974%22%2C%225965326176%22%2C%226024781859%22%2C%22664433854%22%2C%22707068981%22%2C%22794630620%22%2C%22823395680%22%2C%22853035674%22%2C%22910562342%22%5D%2C%22segmentQuery%22:%22#interneuron%20#L2%20NSe%3E=800%20%3CNSi%22%2C%22colorSeed%22:4270253886%2C%22name%22:%22c3%20segmentation%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://gs://h01-release/data/20210601/layers%22%2C%22tab%22:%22source%22%2C%22selectedAlpha%22:0.3%2C%22objectAlpha%22:0.2%2C%22segments%22:%5B%221%22%2C%222%22%2C%223%22%2C%224%22%2C%225%22%2C%226%22%2C%227%22%5D%2C%22segmentQuery%22:%221%2C2%2C3%2C4%2C5%2C6%2C7%22%2C%22name%22:%22cortical%20layers%22%2C%22visible%22:false%7D%5D%2C%22showSlices%22:false%2C%22prefetch%22:false%2C%22selectedLayer%22:%7B%22row%22:1%2C%22flex%22:1.55%2C%22size%22:309%2C%22layer%22:%224nm%20EM%22%7D%2C%22layout%22:%7B%22type%22:%22xy-3d%22%2C%22orthographicProjection%22:true%7D%2C%22selection%22:%7B%22row%22:2%2C%22flex%22:0.45%2C%22size%22:309%2C%22visible%22:false%7D%7D">link</a>)</p></figcaption></figure></div><div class=flex></div></section><section id=section-2 class=repeated-heading><h2 id=available-datasets-1>Available datasets</h2><h3 id=helmholtz-imaging-collaboration-use-case>Helmholtz Imaging collaboration use case</h3><aside class=notes>In collaboration with Prof. Dr. Mathias Treier from MDC Berlin, the Helmholtz Imaging Support team is utilizing
Neuroglancer to visualize mice brains with different genetic mutations and corresponding brain regions.</aside><div class=center><figure><img src=https://ida-mdc.github.io/workshop-visualization/img/neuroglancer-treier3.png height=600px></figure></div><div style=flex:1></div><div class=citations><ul><li><a href=https://www.mdc-berlin.de/de/person/prof-dr-mathias-treier>Mathias Treier, MDC Berlin</a></li></ul></div></section><section id=section-3><h2 id=dataset-requirements>Dataset requirements</h2><aside class=notes>For Neuroglancer to visualize data, the data must be <strong>available through streams</strong>, either locally or remotely. Neuroglancer streams data on demand, so it’s crucial that data be served via an HTTP or other streaming protocol. Whether data is hosted locally or on a cloud, the tool fetches the portions needed as the user navigates through the 3D space.</aside><h3 id=supported-data-types>Supported Data Types</h3><ul><li><a href=src/datasource/precomputed>Neuroglancer precomputed format</a></li><li><a href=src/datasource/n5>N5</a></li><li><a href=src/datasource/zarr>Zarr v2/v3</a> (including OME-ZARR)</li><li><a href=python/README.md>Python in-memory volumes</a> (with automatic mesh generation)</li><li><a href=https://bossdb.org/>BOSS</a> , <a href=https://github.com/janelia-flyem/dvid>DVID</a>, <a href=https://github.com/saalfeldlab/render>Render</a>, <a href=https://www.nitrc.org/projects/nifti>Single NIfTI files</a>, <a href=https://github.com/google/neuroglancer/tree/master/src/datasource/deepzoom>Deep Zoom images</a></li></ul><div style=flex:1></div><div class=citations><ul><li><a href=https://github.com/google/neuroglancer>https://github.com/google/neuroglancer</a></li></ul></div></section><section id=section-4><h2 id=data-preparation>Data preparation</h2><h3 id=volumetric-images>Volumetric images</h3><aside class=notes>This section will cover how to prepare volumetric data (like TIFFs representing Z slices) for use in Neuroglancer. We’ll convert the data into <strong>ZARR</strong> format first and then into <strong>OME-ZARR</strong> format for optimal streaming in Neuroglancer.</aside><div class=flex></div><div class=horizontal><div><h3 id=conversion-steps>Conversion Steps:</h3><ul><li><strong>Step 1</strong>: Convert the TIFF slices into <strong>ZARR</strong> format, which supports chunked, compressed storage.</li><li><strong>Step 2</strong>: Convert the <strong>ZARR</strong> files into <strong>OME-ZARR</strong> format, which includes metadata for biological imaging data and supports better integration with visualization tools like Neuroglancer.</li></ul><div class=center><a href="https://gitlab.com/ida-mdc/24-treier/-/blob/main/Convert%20TIFF%20slices%20to%20OME-ZARR.ipynb?ref_type=heads"><strong>Notebook: TIFF slices to multiscale OME-ZARR</strong></a></div></div><figure><img src=https://ida-mdc.github.io/workshop-visualization/img/neuroglancer-treier.png></figure></div><div class=flex></div></section><section id=section-5 class=repeated-heading><h2 id=data-preparation-1>Data preparation</h2><h3 id=annotations>Annotations</h3><aside class=notes>In addition to volumetric data, you can also visualize annotations in Neuroglancer. This section will show how to convert a list of 3D points (e.g., cells, features) into <strong>CloudVolume annotations</strong>, which Neuroglancer can render as interactive points in the 3D space.</aside><div class=flex></div><div class=horizontal><div><h3 id=conversion-steps>Conversion Steps:</h3><ul><li><strong>Step 1</strong>: Prepare a list of points or annotations that describe features in your dataset (e.g., 3D coordinates for cell locations).</li><li><strong>Step 2</strong>: Convert the list of points into <strong>CloudVolume annotations</strong>.</li></ul><div class=center><a href="https://gitlab.com/ida-mdc/24-treier/-/blob/main/Convert%20cells%20to%20precomputed.ipynb?ref_type=heads"><strong>Notebook: JSON point locations to Neuroglancer Precomputed annotations</strong></a></div></div><figure><img src=https://ida-mdc.github.io/workshop-visualization/img/neuroglancer-treier2.png></figure></div><div class=flex></div></section><section id=section-6><h2 id=streaming-data-locally>Streaming data locally</h2><aside class=notes>For local visualization, you can use a <strong>simple Python server</strong> to serve your data locally to Neuroglancer. This allows you to view your data without hosting it on a remote server. You can use the default Neuroglancer demo page to visualize the data from your local machine.</aside><h3 id=with-python>With Python:</h3><ul><li><strong>Step 1</strong>: Use Python’s built-in HTTP server to serve the data directory:<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python3 -m http.server
</span></span></code></pre></div></li><li><strong>Step 2</strong>: Open the <strong>Neuroglancer demo page</strong> and enter the local URL of your data (e.g.,
<code>zarr://http://localhost:8000/my-dataset.ome.zarr</code>).</li></ul></section><section id=section-7><h2 id=sharing-views>Sharing views</h2><aside class=notes>Neuroglancer makes it easy to share views with collaborators by simply copying the <strong>URL</strong>. The URL encodes the entire view configuration, including which datasets are loaded and how they are visualized. You can also access the <strong>JSON configuration</strong> directly from the interface, which can be useful for scripting and automating views.</aside><h3 id=example-of-json-in-url>Example of JSON in URL:</h3><ul><li>Copy the URL from your browser, and you’ll notice that it contains encoded parameters for layers, views, and more.</li><li>The <strong>JSON configuration</strong> embedded in the URL can be customized to adjust the view programmatically.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;dimensions&#34;</span>: {<span style=color:#960050;background-color:#1e0010>...</span>},
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;position&#34;</span>: [
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>3744.089599609375</span>,
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>4562.4326171875</span>,
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>837.0703125</span>
</span></span><span style=display:flex><span>  ],
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;layers&#34;</span>: [
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;image&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;source&#34;</span>: <span style=color:#e6db74>&#34;zarr://https://hifis-storage.desy.de:2443/Helmholtz/HIP/collaborations/2405_MDC_Treier/public/G5111-S4/647nm_cFOS&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;tab&#34;</span>: <span style=color:#e6db74>&#34;rendering&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;shaderControls&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;normalized&#34;</span>: {
</span></span><span style=display:flex><span>          <span style=color:#f92672>&#34;range&#34;</span>: [
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>500</span>
</span></span><span style=display:flex><span>          ]
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>      },
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;crossSectionRenderScale&#34;</span>: <span style=color:#ae81ff>0.47742080195520836</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;cFOS&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;annotation&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;source&#34;</span>: <span style=color:#e6db74>&#34;precomputed://https://hifis-storage.desy.de:2443/Helmholtz/HIP/collaborations/2405_MDC_Treier/public/G5111-S4/cells&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;tab&#34;</span>: <span style=color:#e6db74>&#34;source&#34;</span>,
</span></span><span style=display:flex><span>      <span style=color:#f92672>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Cells&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>  ],
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;selectedLayer&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;visible&#34;</span>: <span style=color:#66d9ef>true</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;layer&#34;</span>: <span style=color:#e6db74>&#34;cFOS&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></section><section id=section-8><h2 id=programmatically-generate-url>Programmatically generate URL</h2><aside class=notes>The <strong>URL</strong> in Neuroglancer can also be generated programmatically, allowing you to automate the setup of a visualization without manually configuring the layers. This is especially useful for generating consistent views across multiple datasets.</aside><p>Link to the full notebook showing how to generate a Neuroglancer URL programmatically:</p><div class=center><a href="https://gitlab.com/ida-mdc/24-treier/-/blob/main/Generate%20Neuroglancer%20URLs.ipynb?ref_type=heads"><strong>Notebook: Generate Neuroglancer URLs</strong></a></div></section><section id=section-9><h2 id=data-hosting-for-neuroglancer>Data hosting for Neuroglancer</h2><aside class=notes>There are several options for <strong>hosting data</strong> for Neuroglancer. Data can be hosted locally or on cloud storage (e.g.,
AWS, Google Cloud). Hosting data remotely allows for easier sharing and collaboration.</aside><ul><li><strong>Local Hosting</strong>: Serve data from your own machine or institution’s servers.</li><li><strong>AWS S3 or Google Cloud Storage</strong>: Store large datasets and stream them to Neuroglancer from the cloud.</li><li><strong>Scientific Data Services</strong>: e.g. <a href=https://www.ebi.ac.uk/bioimage-archive/>BioImage Archive</a></li><li><strong>Do you know other compatible hosting places?</strong> Let us know!</li></ul></section><section id=section-10 class=repeated-heading><h2 id=data-hosting-for-neuroglancer-1>Data hosting for Neuroglancer</h2><h3 id=helmholtz-storage-compatible-to-neuroglancer>Helmholtz storage compatible to Neuroglancer</h3><p><strong>Collaboration between Helmholtz Imaging and HIFIS at DESY, with the support of the Jülich Cluster.</strong></p><div class=flex></div><div class=horizontal><div class=flex></div><figure class=image-right><img src=https://ida-mdc.github.io/workshop-visualization/img/logos/HIFIS_Logo_short_RGB_cropped.svg height=60px></figure><figure class=image-right><img src=https://ida-mdc.github.io/workshop-visualization/img/logos/Logo_des_Forschungszentrums_J%C3%BClich_seit_2018.svg height=70px></figure></div><div class=flex></div><aside class=notes>Helmholtz employees have access to <strong>dCache InfiniteSpace</strong> and the <strong>Helmholtz Imaging Neuroglancer instance</strong>,
which provides a convenient way to host and stream datasets without size limitation.</aside><ul><li><strong>dCache / InfiniteSpace</strong>: Secure, scalable storage solution for Helmholtz researchers to host and stream datasets.
The data hosted on the storage can be shared publicly.</li></ul><p><strong>Steps:</strong></p><ol><li>Authenticate yourself to access the storage using AAI.</li><li>Upload the data, i.e. using <code>rclone</code> command line tool or the <code>Rclone Browser</code> GUI</li></ol><div style=flex:1></div><div class=citations><ul><li><a href=https://hifis.net/doc/cloud-services/Storage_DESY/>HIFIS dCache documentation</a></li><li><a href=https://hifis-storage.desy.de/>https://hifis-storage.desy.de</a></li></ul></div></section><section id=section-11 class=repeated-heading><h2 id=data-hosting-for-neuroglancer-2>Data hosting for Neuroglancer</h2><h3 id=helmholtz-neuroglancer-instance>Helmholtz Neuroglancer Instance</h3><aside class=notes>The <strong>Helmholtz Imaging Neuroglancer instance</strong> can be used to stream data from the <strong>dCache InfiniteSpace</strong>
directly into the browser. Due to access rights setup of the <strong>dCache InfiniteSpace</strong>, one can&rsquo;t use the default Neuroglancer Demo site
with that storage. The <strong>Helmholtz Imaging Neuroglancer instance</strong> is set up with the permission to render data
from dCache.</aside><ul><li><strong>Helmholtz Imaging Neuroglancer instance</strong>: A dedicated Neuroglancer instance for the Helmholtz community.</li></ul><p><strong>Steps:</strong></p><ol><li>In <a href=https://hifis-storage.desy.de>https://hifis-storage.desy.de</a>, right click on the dataset you want to stream and click &ldquo;Get WebDAV link&rdquo;</li><li>Replace the <code>2880</code> port with <code>2443</code></li><li>Open <a href=https://neuroglancer.helmholtz-imaging.de>https://neuroglancer.helmholtz-imaging.de</a></li><li>Add your dataset using the modified URL</li></ol></section></div><div class=reveal-footer><span>2024</span> | <span><b>HELMHOLTZ IMAGING</b></span><span><span><a class=hidden-in-page href="?view=scroll"><strong>Exit slides</strong></a></span></span></div></div></main><footer></footer></body></html>