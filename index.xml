<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>3D Data Visualization Workshop</title><link>https://ida-mdc.github.io/workshop-visualization/</link><description>Recent content on 3D Data Visualization Workshop</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 09 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://ida-mdc.github.io/workshop-visualization/index.xml" rel="self" type="application/rss+xml"/><item><title>3D Data Visualization Workshop</title><link>https://ida-mdc.github.io/workshop-visualization/visualization-workshop/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/visualization-workshop/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>&lt;unlisted/>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;div>
 &lt;p>Hi, I&amp;rsquo;m Deborah, head of the Helmholtz Imaging Support Unit at MDC.&lt;/p>
&lt;h3 id="meet-the-helmholtz-imaging-support-units">Meet the Helmholtz Imaging Support Units!&lt;/h3>
&lt;p>We are here to support you in case you have any questions or need support.&lt;/p>
&lt;h3 id="-working-in-close-collaboration-with-the-helmholtz-imaging-research-units">.. working in close collaboration with the Helmholtz Imaging Research Units.&lt;/h3>
&lt;div class="logos">
 &lt;img src="https://ida-mdc.github.io/workshop-visualization/img/logos/desy.png"/>
 &lt;img src="https://ida-mdc.github.io/workshop-visualization/img/logos/dkfz.png"/>
 &lt;img src="https://ida-mdc.github.io/workshop-visualization/img/logos/mdc.png"/>
&lt;/div>
&lt;/div>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/people/hi-support-staff.jpg"
 alt="Members of all 3 Helmholtz Imaging Support Units at DESY, DKFZ, and MDC.">&lt;figcaption>
 &lt;p>Members of all 3 Helmholtz Imaging Support Units at DESY, DKFZ, and MDC.&lt;/p></description></item><item><title>Choosing colors for scientific 3D renderings</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-choosing-colors/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-choosing-colors/</guid><description>&lt;h2 id="color-representation-in-digital-programs">Color Representation in Digital Programs&lt;/h2>
&lt;aside class="notes">
 Colors in digital visualizations are represented using different models, such as &lt;strong>HEX&lt;/strong>, &lt;strong>RGB&lt;/strong>, and &lt;strong>HSL&lt;/strong>.
Digital programs might use different representations of colors - understanding how these models work can help you
apply colors across tools.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;div>
 &lt;h4>RGB color representation: &lt;span style="color: black;">rgb(&lt;/span>&lt;span style="color: red;">255&lt;/span>, &lt;span 
 style="color: green; ">87&lt;/span>,&lt;span style="color: blue;">51&lt;/span>&lt;span style="color: black;">)&lt;/span>&lt;/h4>
&lt;aside class="notes">
 &lt;ul>
&lt;li>Red, Green, Blue values (0-255)&lt;/li>
&lt;li>Example: &lt;code>rgb(255, 87, 51)&lt;/code> representing orange&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;h4>HEX color representation: &lt;span style="color: black;">#&lt;/span>&lt;span style="color: red;">FF&lt;/span>&lt;span 
 style="color: green; ">57&lt;/span>&lt;span style="color: blue;">33&lt;/span>&lt;span style="color: black;">&lt;/span>&lt;/h4>
&lt;aside class="notes">
 &lt;ul>
&lt;li>Six-character code for RGB, encoded in hexadecimal&lt;/li>
&lt;li>two characters for each of the Red, Green, and Blue channels&lt;/li>
&lt;li>Example: &lt;code>#FF5733&lt;/code> represents orange, a color with maximum red (&lt;code>FF&lt;/code>), moderate green (&lt;code>57&lt;/code>), and low blue (&lt;code>33&lt;/code>)&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;h4>HSL color representation: &lt;span style="color: black;">hsl(&lt;/span>&lt;span style="color: #FF5733;">9&lt;/span>&lt;span 
 style="color: black; ">, 100%, 60%)&lt;/span>&lt;/h4>
&lt;aside class="notes">
 &lt;ul>
&lt;li>Hue (0-360 degrees), Saturation &amp;amp; Lightness (0-100%)&lt;/li>
&lt;li>Example: &lt;code>hsl(9, 100%, 60%)&lt;/code> represents orange, with a hue of 9°, fully saturated, and 60% lightness&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;/div>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/AdditiveColor.svg"
 alt="Additive color mixing with Red, Green and Blue.">&lt;figcaption>
 &lt;p>Additive color mixing with Red, Green and Blue.&lt;/p></description></item><item><title>Converting Volumes to Meshes with VTK</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-conversion/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-conversion/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;aside class="notes">
 In this tutorial, we will use &lt;strong>VTK&lt;/strong> to convert 3D volumetric datasets (e.g., labelmaps, masks, and raw data) into 3D meshes. This process is particularly useful for creating surfaces that can be used in 3D visualizations, simulations, or exported to Blender for further processing. You will also learn how to optimize these meshes by decimating and smoothing them.
&lt;/aside>
&lt;ul>
&lt;li>&lt;strong>VTK&lt;/strong> provides robust tools for generating meshes from volumes, including labelmaps and raw pixel data.&lt;/li>
&lt;li>&lt;strong>FlyingEdges3D&lt;/strong> is a highly efficient algorithm for generating iso-surfaces from volumetric data.&lt;/li>
&lt;li>VTK supports advanced options for mesh optimization, including &lt;strong>smoothing&lt;/strong> and &lt;strong>decimation&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="http://en.wikipedia.org/wiki/Special:BookSources/978-1-930934-19-1">Schroeder, Will; Martin, Ken; Lorensen, Bill (2006), The Visualization Toolkit (4th ed.), Kitware, ISBN 978-1-930934-19-1&lt;/a>, &lt;a href="https://vtk.org/">https://vtk.org/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="solution-to-run-conversion-code-automatically">Solution to run conversion code automatically&lt;/h2>
&lt;aside class="notes">
 This tutorial will guide you through using a Python based solution for volume to mesh conversion. We will look
into the details of the code in the following slides.
&lt;/aside>
&lt;div class="solution-in-tutorial">
 &lt;p>
 To simplify and unify solutions used in our tutorials, we use Album, a tool for capturing and sharing specific software use cases in dedicated virtual environments.
 &lt;br/>&lt;br/>
 Click the solution box next to this text and follow the displayed usage instructions to run the solution either from command line or graphical interface.
 &lt;/p></description></item><item><title>Cutting mesh structures in Blender</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-cutting-volumes-blender/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-cutting-volumes-blender/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;aside class="notes">
 &lt;p>Cutting into mesh structures in Blender can be incredibly helpful for scientific visualization, especially when dealing with complex datasets. By cutting into an object, you can reveal internal structures that would otherwise remain hidden, providing deeper insights into the data.&lt;/p>
&lt;p>For example, in our research, we visualized the structure of a &lt;strong>beta cell&lt;/strong> from the following publication. We cut into the 3D volume, revealing important internal details that ended up getting featured on the cover of the journal.&lt;/p></description></item><item><title>How to install and use Album - a tool for decentralized software use case sharing</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-album-user/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-album-user/</guid><description>&lt;h2 id="why-does-album-exist">Why does Album exist?&lt;/h2>
&lt;div class="center">
 &lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/album/album-comparison.png">
&lt;/figure>

&lt;/div>
&lt;aside class="notes">
 &lt;ul>
&lt;li>In science, commercial tools exist and can be very useful, but to push the boundaries of knowledge and stay ahead of new developments, scientists often rely on &lt;strong>open-source tools&lt;/strong> and &lt;strong>custom software&lt;/strong>.&lt;/li>
&lt;li>This results in scientists needing to figure out which tools solve their problems, how to install them, and how to use them, which leads to a diverse and sometimes confusing ecosystem.&lt;/li>
&lt;li>While there are IT solutions that help with &lt;strong>unifying software use cases&lt;/strong> (like Docker or virtual environments), these tools are often challenging for non-computer experts due to their complexity and the risk of version conflicts.&lt;/li>
&lt;li>&lt;strong>Album&lt;/strong> exists to solve this problem by making it easier to manage, share, and use scientific software solutions without requiring deep technical expertise.&lt;/li>
&lt;/ul>

&lt;/aside>
&lt;hr>
&lt;h2 id="how-does-it-work">How does it work?&lt;/h2>
&lt;aside class="notes">
 &lt;ul>
&lt;li>Each &lt;strong>Album solution&lt;/strong> is essentially a &lt;strong>single script&lt;/strong> (written in Python) that wraps a specific &lt;strong>software use
case&lt;/strong>.&lt;/li>
&lt;li>This script describes:
&lt;ul>
&lt;li>The &lt;strong>software dependencies&lt;/strong> required for the solution.&lt;/li>
&lt;li>The &lt;strong>metadata&lt;/strong> of the use case (such as who to cite, arguments available, and links to further documentation).&lt;/li>
&lt;li>The &lt;strong>launch parameters&lt;/strong> and run routine for the specific use case.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Album handles the entire installation process by automatically installing a virtual environment for each solution
individually, and it offers a clean, uniform interface to run different tools, both from a graphical interface or
from command line.&lt;/li>
&lt;/ul>

&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/album/album-schema-people-big.png"
 alt="Solutions can wrap different tools and libraries. They can be bundled in catalogs and shared with users who don&amp;rsquo;t have any coding experience." width="900">&lt;figcaption>
 &lt;p>Solutions can &lt;strong>wrap different tools and libraries&lt;/strong>. They can be bundled in catalogs and &lt;strong>shared with users who don&amp;rsquo;t have any coding experience&lt;/strong>.&lt;/p></description></item><item><title>Image Prevalidation</title><link>https://ida-mdc.github.io/workshop-visualization/album-solutions/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/album-solutions/</guid><description>&lt;h1 id="test">Test&lt;/h1>
&lt;pre class="mermaid">sequenceDiagram
 participant Alice
 participant Bob
 Alice->>John: Hello John, how are you?
 loop Healthcheck
 John->>John: Fight against hypochondria
 end
 Note right of John: Rational thoughts &lt;br/>prevail!
 John-->>Alice: Great!
 John->>Bob: How about you?
 Bob-->>John: Jolly good!
&lt;/pre>
&lt;hr>
&lt;h2 id="test-2">Test 2&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sudo apt install something
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Rendering in Blender</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-rendering-blender/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-rendering-blender/</guid><description>&lt;h2 id="create-a-new-blender-scene">Create a New Blender Scene&lt;/h2>
&lt;aside class="notes">
 To start, launch Blender and create a new scene to begin setting up your rendering environment. You can save this scene and reload it later with the same solution, preserving your work.
&lt;/aside>
&lt;ul>
&lt;li>&lt;strong>Install Blender&lt;/strong> from the official website: &lt;a href="https://www.blender.org/download/">https://www.blender.org/download/&lt;/a>&lt;/li>
&lt;li>&lt;strong>Launch Blender&lt;/strong> and create a new scene.&lt;/li>
&lt;/ul>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://www.blender.org">Blender Online Community. Blender - a 3D modelling and rendering package, Stichting Blender Foundation, Amsterdam.&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="general-usage">General Usage&lt;/h2>
&lt;h3 id="import-mesh-files">Import Mesh Files&lt;/h3>
&lt;aside class="notes">
 Blender allows you to import meshes, such as &lt;strong>STL files&lt;/strong>, from previous steps in the workflow. These might need to be resized or adjusted for Blender&amp;rsquo;s scale.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>Go to &lt;code>File &amp;gt; Import &amp;gt; STL (.stl)&lt;/code>&lt;/li>
&lt;li>Imported objects might be scaled too large or small. To adjust, go to the &lt;strong>Layout&lt;/strong> tab, select the object, and press &lt;code>n&lt;/code> to open the options for scaling.&lt;/li>
&lt;/ul>
&lt;figure class="center">&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-import-stl.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;hr>
&lt;h2 id="general-usage-1">General Usage&lt;/h2>
&lt;h3 id="toggle-quad-view">Toggle Quad View&lt;/h3>
&lt;aside class="notes">
 The quad view gives you orthogonal views (top, side, and front) simultaneously, which is useful for positioning objects accurately.
&lt;/aside>
&lt;ul>
&lt;li>To enable &lt;strong>Quad View&lt;/strong>, go to &lt;strong>View &amp;gt; Area &amp;gt; Toggle Quad View&lt;/strong>&lt;/li>
&lt;/ul>
&lt;figure class="center">&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-quad-view.png">
&lt;/figure>
&lt;hr>
&lt;h2 id="general-usage-2">General Usage&lt;/h2>
&lt;h3 id="view-from-the-camera">View from the Camera&lt;/h3>
&lt;aside class="notes">
 To see what the camera is capturing, you can switch to the camera view and adjust the perspective for rendering.
&lt;/aside>
&lt;ul>
&lt;li>Go to &lt;strong>View &amp;gt; Viewpoint &amp;gt; Camera&lt;/strong> for switching to camera view&lt;/li>
&lt;li>Go to &lt;strong>View &amp;gt; Align View &amp;gt; Align Active Camera to View&lt;/strong> for adjusting the camera to the current view&lt;/li>
&lt;/ul>
&lt;figure class="center">&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-align-camera.png">
&lt;/figure>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/render/cameras.html#cameras">Blender Documentation: Cameras&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="performance">Performance&lt;/h2>
&lt;h3 id="set-view-parameters">Set View Parameters&lt;/h3>
&lt;aside class="notes">
 Adjusting viewport shading and view parameters can improve performance or give you a clearer preview of your rendering, depending on your hardware.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>Use the &lt;strong>Viewport Shading&lt;/strong> buttons in the top right corner to change shading modes:&lt;/li>
&lt;li>&lt;strong>Rendered mode&lt;/strong> for full previews.&lt;/li>
&lt;li>&lt;strong>Material preview mode&lt;/strong> for a balance between performance and detail.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-viewports.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/editors/3dview/display/shading.html">Blender Documentation: Viewport Shading&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="performance-1">Performance&lt;/h2>
&lt;h3 id="adjust-gpu-settings">Adjust GPU Settings&lt;/h3>
&lt;aside class="notes">
 Blender relies heavily on your system’s GPU for rendering. Ensuring your GPU is properly configured will improve performance and the quality of your renderings.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>Blender requires a GPU with at least &lt;strong>2GB of VRAM&lt;/strong>.&lt;/li>
&lt;li>To configure your GPU, go to &lt;code>Edit &amp;gt; Preferences... &amp;gt; System &amp;gt; Cycles Render Devices&lt;/code>&lt;/li>
&lt;li>Ensure that &lt;strong>GPU Compute&lt;/strong> is selected under &lt;code>Cycles&lt;/code> as the &lt;strong>Render Engine&lt;/strong>.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-gpu-settings.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/render/cycles/gpu_rendering.html">Blender Documentation: GPU Rendering&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="performance-2">Performance&lt;/h2>
&lt;h3 id="adjust-render-parameters">Adjust Render Parameters&lt;/h3>
&lt;aside class="notes">
 Tweaking render parameters can improve the visual quality of your render, especially when working with reflective or translucent materials such as glass.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-render-settings.png">
&lt;/figure>
&lt;ul>
&lt;li>In the &lt;strong>Rendering tab&lt;/strong>, under &lt;code>Render Properties&lt;/code>, increase values in the &lt;strong>Light Paths&lt;/strong> section with glass or
glossy materials, or decrease these values to improve performance.&lt;/li>
&lt;li>In &lt;strong>Output Properties&lt;/strong>, Adjust the resolution percentage for fast preview renderings or detailed print renderings.&lt;/li>
&lt;/ul>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/render/index.html">Blender Documentation: Rendering&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="object-appearance">Object appearance&lt;/h2>
&lt;h3 id="smooth-shading-for-objects">Smooth Shading for Objects&lt;/h3>
&lt;aside class="notes">
 Smoothing the shading of objects can make your mesh appear less blocky and more polished, especially for organic shapes.
&lt;/aside>
&lt;ul>
&lt;li>Right-click the object and select &lt;strong>Shade Smooth&lt;/strong> to apply smooth shading.&lt;/li>
&lt;/ul>
&lt;figure class="center">&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-shade-smooth.png">
&lt;/figure>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/scene_layout/object/editing/shading.html">Blender Documentation: Shading&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="object-appearance-1">Object appearance&lt;/h2>
&lt;h3 id="apply-material-to-object">Apply Material to Object&lt;/h3>
&lt;aside class="notes">
 Blender’s &lt;strong>Shading Tab&lt;/strong> allows you to apply complex materials to your objects, including gloss, transparency, and other physical properties. Experimenting with the &lt;code>Principled BSDF&lt;/code> shader can give you a wide range of effects.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>Go to the &lt;strong>Shading&lt;/strong> tab and select &lt;strong>Use Nodes&lt;/strong>.&lt;/li>
&lt;li>Explore the options under &lt;strong>Principled BSDF&lt;/strong>:&lt;/li>
&lt;li>Increase &lt;strong>Subsurface&lt;/strong> to make materials look soft.&lt;/li>
&lt;li>Use the &lt;code>Add &amp;gt; Search&lt;/code> function to find shaders like &lt;strong>Glass&lt;/strong> for transparency effects.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-material-nodes.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/render/materials/introduction.html">Blender Documentation: Materials&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="denoising-the-render">Denoising the Render&lt;/h2>
&lt;aside class="notes">
 Blender includes a denoising feature to remove noise from rendered images, improving quality without significantly increasing render time.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>In the &lt;strong>Rendering Tab&lt;/strong>, under &lt;code>View Layer Properties&lt;/code>:&lt;/li>
&lt;li>Under &lt;code>Passes &amp;gt; Data&lt;/code>, select &lt;strong>Denoising Data&lt;/strong>.&lt;/li>
&lt;li>In the &lt;strong>Compositing Tab&lt;/strong>:&lt;/li>
&lt;li>Check the &lt;strong>Use Nodes&lt;/strong> checkbox.&lt;/li>
&lt;li>Add a &lt;strong>Denoise&lt;/strong> node (&lt;code>Add &amp;gt; Search &amp;gt; Denoise&lt;/code>) and connect the nodes as follows:
&lt;ul>
&lt;li>Connect &lt;code>Render Denoising Normal&lt;/code> and &lt;code>Denoising Albedo&lt;/code> to &lt;code>Normal&lt;/code> and &lt;code>Albedo&lt;/code> of the Denoise node.&lt;/li>
&lt;li>Connect &lt;code>Image&lt;/code> from the Denoise node to &lt;code>Image&lt;/code> of the Composite node.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-denoising.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://docs.blender.org/manual/en/latest/render/cycles/optimizations/reducing_noise.html">Blender Documentation: Reducing Noise&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="happy-rendering">Happy rendering!&lt;/h2>
&lt;aside class="notes">
 Once you&amp;rsquo;ve completed these steps, you will have a beautifully rendered scene in Blender. Feel free to explore
Blender&amp;rsquo;s other features, experiment with different materials, lighting setups, and camera angles to get the best results.
&lt;/aside>
&lt;figure class="center">&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/blender-render-result.png" width="85%">
&lt;/figure></description></item><item><title>Rendering meshes in VTK</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-rendering-vtk/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-mesh-rendering-vtk/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;aside class="notes">
 &lt;strong>VTK&lt;/strong> is a powerful toolkit for rendering 3D meshes, and this tutorial focuses on using the provided solution for rendering scientific 3D datasets. We will explore not just how to run the solution, but also how the underlying Python code works, step by step. You will learn the foundational concepts of VTK while also understanding how to extend the code for your own datasets.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>Python based 3D visualization tool&lt;/li>
&lt;li>Supports various formats (STL, OBJ, PLY, ..)&lt;/li>
&lt;li>Advanced rendering capabilities (volume rendering, surface rendering, light and material configuration)&lt;/li>
&lt;li>Supports programmatic animations&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/vtk-rendering-slicing.png">
&lt;/figure>

&lt;/div>
&lt;div class="flex">&lt;/div>


&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="http://en.wikipedia.org/wiki/Special:BookSources/978-1-930934-19-1">Schroeder, Will; Martin, Ken; Lorensen, Bill (2006), The Visualization Toolkit (4th ed.), Kitware, ISBN 978-1-930934-19-1&lt;/a>, &lt;a href="https://vtk.org/">https://vtk.org/&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="solution-to-run-vtk-code">Solution to run VTK code&lt;/h2>
&lt;aside class="notes">
 This tutorial will guide you through using Album&amp;rsquo;s &lt;strong>visualize-meshes-vtk&lt;/strong> solution, showcasing how you can interact with 3D meshes and volume data using VTK, all while running it in an isolated environment.
&lt;/aside>
&lt;div class="solution-in-tutorial">
 &lt;p>
 To simplify and unify solutions used in our tutorials, we use Album, a tool for capturing and sharing specific software use cases in dedicated virtual environments.
 &lt;br/>&lt;br/>
 Click the solution box next to this text and follow the displayed usage instructions to run the solution either from command line or graphical interface.
 &lt;/p></description></item><item><title>Solutions</title><link>https://ida-mdc.github.io/workshop-visualization/solutions/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/solutions/</guid><description>&lt;section>No data found in .Site.Data&lt;/section></description></item><item><title>TODO</title><link>https://ida-mdc.github.io/workshop-visualization/todo/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/todo/</guid><description>&lt;ul>
&lt;li>
&lt;p>General:&lt;/p>
&lt;ul>
&lt;li>TODO slido license and questions!&lt;/li>
&lt;li>TODO make proper &amp;ldquo;how to run solution&amp;rdquo; page and link to it from solutions!&lt;/li>
&lt;li>TODO move to github&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>After presentation:&lt;/p>
&lt;ul>
&lt;li>TODO redeploy rest without defaults in channels&lt;/li>
&lt;li>TODO add impressum&lt;/li>
&lt;li>TODO make proper landing page&lt;/li>
&lt;li>TODO add comment thingy&lt;/li>
&lt;li>TODO add readme&lt;/li>
&lt;li>TODO add header&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Volumetric data rendering with Neuroglancer</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-neuroglancer/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-neuroglancer/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;aside class="notes">
 &lt;p>&lt;strong>Neuroglancer&lt;/strong> is a web-based tool for visualizing large-scale 3D datasets such as brain volumes, microscopy
images, and annotations. Neuroglancer allows you to stream volumetric datasets for interactive exploration in the browser.&lt;/p>
&lt;p>This showcase will demonstrate the process of preparing your data for Neuroglancer, streaming it
locally or remotely, and working with the Neuroglancer interface to adjust views, add annotations, and share visualizations with collaborators.&lt;/p>

&lt;/aside>
&lt;h3 id="main-features">Main Features:&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Voxel-based rendering&lt;/strong>: Efficiently visualize large 3D datasets by streaming the data directly into the browser.&lt;/li>
&lt;li>&lt;strong>Support for multiple data formats&lt;/strong>: Neuroglancer works with a variety of formats like &lt;strong>ZARR&lt;/strong> and &lt;strong>OME-ZARR&lt;/strong> for volumetric images, as well as annotation formats.&lt;/li>
&lt;li>&lt;strong>Interactive, shareable views&lt;/strong>: Customize and share views by copying the URL directly from the Neuroglancer interface.&lt;/li>
&lt;/ul>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://github.com/google/neuroglancer">Neuroglancer, Google Connectomics Team&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="available-datasets">Available datasets&lt;/h2>
&lt;h2 id="popular-datasets-using-neuroglancer">Popular datasets using Neuroglancer&lt;/h2>
&lt;aside class="notes">
 Neuroglancer has been used to visualize several large-scale, high-resolution datasets, especially in the fields of neuroscience, biology, and medical imaging. These datasets often involve volumetric scans, such as brain structures, organs, or entire organisms, making Neuroglancer an invaluable tool for researchers who need interactive, 3D visualizations of such complex data.
&lt;/aside>
&lt;div class="flex">&lt;/div>
&lt;div class="horizontal">
 &lt;ul>
&lt;li>&lt;strong>&lt;a href="https://www.microns-explorer.org/">MICrONS Explorer&lt;/a>&lt;/strong>: A large-scale dataset from the &lt;strong>MICrONS Project&lt;/strong>, providing high-resolution volumetric reconstructions of a mouse brain.&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.janelia.org/project-team/flyem/hemibrain">FlyEM Hemibrain&lt;/a>&lt;/strong>: This dataset offers a detailed 3D reconstruction of the &lt;strong>Drosophila melanogaster&lt;/strong> brain at nanometer resolution.&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://h01-release.storage.googleapis.com/landing">&amp;ldquo;H01&amp;rdquo; Dataset&lt;/a>&lt;/strong>: 1.4 Petabyte for one cubic millimeter
of the human brain, released by the Harvard University and the Connectomics at Google team.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://ida-mdc.github.io/workshop-visualization/img/the-human-brain.png"
 alt="Screenshot from the H01 Dataset (link)">&lt;figcaption>
 &lt;p>Screenshot from the H01 Dataset (&lt;a href="https://h01-dot-neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B8e-9%2C%22m%22%5D%2C%22y%22:%5B8e-9%2C%22m%22%5D%2C%22z%22:%5B3.3e-8%2C%22m%22%5D%7D%2C%22position%22:%5B332552.65625%2C141535.84375%2C3487.12451171875%5D%2C%22crossSectionScale%22:5.776802800212544%2C%22projectionOrientation%22:%5B0.00491650216281414%2C0.035930924117565155%2C-0.03526147082448006%2C0.9987198710441589%5D%2C%22projectionScale%22:261570.24038807175%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://h01-release/data/20210601/4nm_raw%22%2C%22tab%22:%22source%22%2C%22name%22:%224nm%20EM%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%5B%7B%22url%22:%22precomputed://gs://h01-release/data/20210601/c3%22%2C%22subsources%22:%7B%22default%22:true%2C%22bounds%22:true%2C%22properties%22:true%2C%22mesh%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22precomputed://gs://lichtman-h01-49eee972005c8846803ef58fbd36e049/goog14r0s5c3_new_props/segment_properties%22%5D%2C%22panels%22:%5B%7B%22flex%22:1.55%2C%22tab%22:%22segments%22%7D%5D%2C%22segments%22:%5B%221100054524%22%2C%221115430292%22%2C%2212237931142%22%2C%221333290325%22%2C%221538274151%22%2C%221539076840%22%2C%221594648509%22%2C%221638188509%22%2C%221828951844%22%2C%221915887451%22%2C%221988993337%22%2C%2220070214646%22%2C%222090806103%22%2C%222134549398%22%2C%222178704414%22%2C%222294780853%22%2C%222339328448%22%2C%222499107339%22%2C%222499384877%22%2C%222557789796%22%2C%222673254402%22%2C%2227622860459%22%2C%2227651872764%22%2C%2227870683066%22%2C%222791142865%22%2C%2228000894735%22%2C%2228045909614%22%2C%2228378958224%22%2C%2228409678489%22%2C%2228452985548%22%2C%2228525770719%22%2C%2228643309290%22%2C%2228672203772%22%2C%2228802547903%22%2C%2228803598117%22%2C%2228918216929%22%2C%2229021270843%22%2C%2229182786959%22%2C%2229238417446%22%2C%2229298236361%22%2C%222935896346%22%2C%2229459096371%22%2C%2229618159554%22%2C%2229765396306%22%2C%2229925423252%22%2C%2229938695074%22%2C%2229969547791%22%2C%2230101233972%22%2C%223023633866%22%2C%2230376944711%22%2C%2230406000355%22%2C%223052908678%22%2C%2230668773752%22%2C%2230767987832%22%2C%2230871567933%22%2C%2230974109956%22%2C%2231031989065%22%2C%2231032951251%22%2C%2231061717348%22%2C%2231133932587%22%2C%2231149133165%22%2C%223125564306%22%2C%2231658722916%22%2C%2232444986357%22%2C%223430740099%22%2C%223504577656%22%2C%223518943222%22%2C%223573728110%22%2C%2236123853342%22%2C%2236153829678%22%2C%2236241229806%22%2C%2236284756264%22%2C%2236445761568%22%2C%2236590837294%22%2C%2236619747807%22%2C%2236620463168%22%2C%2236633005581%22%2C%223664545249%22%2C%2236662790455%22%2C%2236678107375%22%2C%2236763714196%22%2C%2236809473223%22%2C%2236822073774%22%2C%2236822262086%22%2C%2236852896228%22%2C%2237173591638%22%2C%2237218168369%22%2C%2237318668413%22%2C%2237319791473%22%2C%2237420743412%22%2C%2237421824682%22%2C%2237463700916%22%2C%2237536734693%22%2C%2237581252436%22%2C%2237594612366%22%2C%2237668755920%22%2C%2237770758892%22%2C%2237801070911%22%2C%2237930756265%22%2C%2237958718097%22%2C%2238018479939%22%2C%2238092682277%22%2C%2238106873604%22%2C%2238208029710%22%2C%2238222309348%22%2C%2238339219897%22%2C%2238368158152%22%2C%2238383402139%22%2C%223839697992%22%2C%2238413115427%22%2C%2238543488421%22%2C%2238573083867%22%2C%2238586823171%22%2C%2238602358951%22%2C%2238717924646%22%2C%2238863556782%22%2C%2238863862489%22%2C%223897678996%22%2C%2238994907574%22%2C%2239023934118%22%2C%2239038491013%22%2C%2239052800624%22%2C%2239081564265%22%2C%2239271712983%22%2C%2239271916939%22%2C%2239359991385%22%2C%223941569746%22%2C%2239505037109%22%2C%2239694250521%22%2C%2240043667040%22%2C%2240102203154%22%2C%2240247497000%22%2C%2240378483178%22%2C%2240407875435%22%2C%2240464862282%22%2C%2241354296446%22%2C%2241630488832%22%2C%224217863883%22%2C%224318903980%22%2C%2245701832369%22%2C%224580553370%22%2C%224698412002%22%2C%224784821941%22%2C%2248079386659%22%2C%224917456198%22%2C%224961186471%22%2C%225062824784%22%2C%225499847526%22%2C%2258866575372%22%2C%2259536235974%22%2C%225965326176%22%2C%226024781859%22%2C%22664433854%22%2C%22707068981%22%2C%22794630620%22%2C%22823395680%22%2C%22853035674%22%2C%22910562342%22%5D%2C%22segmentQuery%22:%22#interneuron%20#L2%20NSe%3E=800%20%3CNSi%22%2C%22colorSeed%22:4270253886%2C%22name%22:%22c3%20segmentation%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://gs://h01-release/data/20210601/layers%22%2C%22tab%22:%22source%22%2C%22selectedAlpha%22:0.3%2C%22objectAlpha%22:0.2%2C%22segments%22:%5B%221%22%2C%222%22%2C%223%22%2C%224%22%2C%225%22%2C%226%22%2C%227%22%5D%2C%22segmentQuery%22:%221%2C2%2C3%2C4%2C5%2C6%2C7%22%2C%22name%22:%22cortical%20layers%22%2C%22visible%22:false%7D%5D%2C%22showSlices%22:false%2C%22prefetch%22:false%2C%22selectedLayer%22:%7B%22row%22:1%2C%22flex%22:1.55%2C%22size%22:309%2C%22layer%22:%224nm%20EM%22%7D%2C%22layout%22:%7B%22type%22:%22xy-3d%22%2C%22orthographicProjection%22:true%7D%2C%22selection%22:%7B%22row%22:2%2C%22flex%22:0.45%2C%22size%22:309%2C%22visible%22:false%7D%7D">link&lt;/a>)&lt;/p></description></item><item><title>Volumetric Dataset Rendering in Python</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-python/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-python/</guid><description>&lt;h2 id="volume-rendering-in-napari">Volume Rendering in napari&lt;/h2>
&lt;aside class="notes">
 &lt;strong>napari&lt;/strong> is a Python-based tool designed for interactive visualization of 2D/3D image data. It supports
multi-channel volume rendering, making it a great option for smaller datasets that require quick exploration in 3D. napari also integrates well with the Python scientific stack, allowing users to run analysis code alongside the visualization.
&lt;/aside>
&lt;ul>
&lt;li>&lt;strong>Interactive visualization and annotation&lt;/strong>: Offers tools for exploring data and annotating images in real-time.&lt;/li>
&lt;li>&lt;strong>Layer-based rendering&lt;/strong>: Supports multiple layers like images, labels, points, and shapes for versatile data representation.&lt;/li>
&lt;li>&lt;strong>Plugin extensibility&lt;/strong>: Easily extendable through plugins to add custom functionality.&lt;/li>
&lt;li>&lt;strong>Integration with Python ecosystem&lt;/strong>: Seamlessly works with NumPy, Dask, and other scientific Python libraries.&lt;/li>
&lt;/ul>
&lt;div style="flex: 1">&lt;/div>
&lt;div class="citations">&lt;ul>
&lt;li>&lt;a href="https://zenodo.org/record/3555620">napari contributors (2019). napari: a multi-dimensional image viewer for python. doi:10.5281/zenodo.3555620&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/napari/napari">https://github.com/napari/napari&lt;/a>&lt;/li>
&lt;/ul>
&lt;/div>

&lt;hr>
&lt;h2 id="volume-rendering-in-napari-1">Volume Rendering in napari&lt;/h2>
&lt;h3 id="solution-to-run-napari-code-through-album">Solution to run napari code through Album&lt;/h3>
&lt;aside class="notes">
 You can follow the &lt;a href="https://napari.org/stable/tutorials/fundamentals/installation.html">official instructions&lt;/a> to
install napari. Alternatively, use this Album solution to run the code / launch napari directly either from command
line or graphical user interface.
&lt;/aside>
&lt;div class="solution-in-tutorial">
 &lt;p>
 To simplify and unify solutions used in our tutorials, we use Album, a tool for capturing and sharing specific software use cases in dedicated virtual environments.
 &lt;br/>&lt;br/>
 Click the solution box next to this text and follow the displayed usage instructions to run the solution either from command line or graphical interface.
 &lt;/p></description></item><item><title>Voxel based volume rendering with BDV based tools</title><link>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-bdv/</link><pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate><guid>https://ida-mdc.github.io/workshop-visualization/tutorial-volume-rendering-bdv/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;aside class="notes">
 &lt;p>&lt;strong>BDV (BigDataViewer)&lt;/strong> is a powerful tool for visualizing large-scale 3D image data, particularly for biological datasets such as volumetric microscopy images. BDV allows for interactive exploration of massive image datasets using a hierarchical storage approach, which enables real-time rendering of very large volumes without overwhelming system memory. BDV is part of a broader family of tools, including &lt;strong>BigVolumeViewer (BVV)&lt;/strong> for large volumetric datasets and &lt;strong>SciView&lt;/strong> for interactive 3D rendering in scientific contexts.&lt;/p></description></item></channel></rss>